{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all data\n",
    "rel_path  = 'Dataset_uptd/all_data'\n",
    "train_path_stutter = rel_path + '/train_data/wp/'\n",
    "train_path_fluent = rel_path + '/train_data/fluet/'\n",
    "test_path_stutter = rel_path + '/train_data/wp/'\n",
    "test_path_fluent = rel_path + '/train_data/fluent/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available is cuda\n",
      "Sample Rate of model: 16000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.69 GiB total capacity; 128.99 MiB already allocated; 18.50 MiB free; 140.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/past/payal/SSL-based-Automatic-Stutter-Detection-/base_wav2vec_full_data_wp.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bideas2.research.northwestern.edu/home/past/payal/SSL-based-Automatic-Stutter-Detection-/base_wav2vec_full_data_wp.ipynb#ch0000002vscode-remote?line=22'>23</a>\u001b[0m bundle \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39mpipelines\u001b[39m.\u001b[39mWAV2VEC2_BASE\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bideas2.research.northwestern.edu/home/past/payal/SSL-based-Automatic-Stutter-Detection-/base_wav2vec_full_data_wp.ipynb#ch0000002vscode-remote?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSample Rate of model:\u001b[39m\u001b[39m\"\u001b[39m, bundle\u001b[39m.\u001b[39msample_rate)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bideas2.research.northwestern.edu/home/past/payal/SSL-based-Automatic-Stutter-Detection-/base_wav2vec_full_data_wp.ipynb#ch0000002vscode-remote?line=25'>26</a>\u001b[0m model_wav2vec \u001b[39m=\u001b[39m bundle\u001b[39m.\u001b[39;49mget_model()\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bideas2.research.northwestern.edu/home/past/payal/SSL-based-Automatic-Stutter-Detection-/base_wav2vec_full_data_wp.ipynb#ch0000002vscode-remote?line=26'>27</a>\u001b[0m \u001b[39m## Convert audio to numpy to wav2vec feature encodings\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bideas2.research.northwestern.edu/home/past/payal/SSL-based-Automatic-Stutter-Detection-/base_wav2vec_full_data_wp.ipynb#ch0000002vscode-remote?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconv_audio_data\u001b[39m (filename) :\n",
      "File \u001b[0;32m~/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=902'>903</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=903'>904</a>\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=904'>905</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=906'>907</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=575'>576</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=581'>582</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=582'>583</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=587'>588</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=575'>576</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=581'>582</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=582'>583</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=587'>588</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 578 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=575'>576</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=581'>582</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=582'>583</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=587'>588</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=596'>597</a>\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=597'>598</a>\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=598'>599</a>\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=599'>600</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=600'>601</a>\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=601'>602</a>\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=602'>603</a>\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=901'>902</a>\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=902'>903</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=903'>904</a>\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> <a href='file:///home/payal/miniconda3/envs/wav2vec/lib/python3.9/site-packages/torch/nn/modules/module.py?line=904'>905</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.69 GiB total capacity; 128.99 MiB already allocated; 18.50 MiB free; 140.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "##################################################################################################\n",
    "# First things first! Set a seed for reproducibility.\n",
    "# https://www.cs.mcgill.ca/~ksinha4/practices_for_reproducibility/\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "##################################################################################################\n",
    "writer = SummaryWriter()\n",
    "writer = SummaryWriter(\"wav2vec_base_model_full_data_wp\")\n",
    "writer = SummaryWriter(comment=\"Full dataset for binary classification word repetion;\")\n",
    "##################################################################################################\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device available is', device)\n",
    "# wav2vec2.0\n",
    "bundle = torchaudio.pipelines.WAV2VEC2_BASE\n",
    "print(\"Sample Rate of model:\", bundle.sample_rate)\n",
    "\n",
    "model_wav2vec = bundle.get_model().to(device)\n",
    "## Convert audio to numpy to wav2vec feature encodings\n",
    "def conv_audio_data (filename) :\n",
    "    waveform, sample_rate = torchaudio.load(filename)\n",
    "    waveform = waveform.to(device)\n",
    "    if sample_rate != bundle.sample_rate:\n",
    "        print('Mismatched sample rate')\n",
    "        waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)\n",
    "    emission, _ = model_wav2vec(waveform)\n",
    "    emission = emission.cpu().detach().numpy()\n",
    "    return emission\n",
    "\n",
    "x_f = []\n",
    "y_f = []\n",
    "x_s = []\n",
    "y_s = []\n",
    "\n",
    "# Convert to the embeddings for training data\n",
    "for filename in glob.glob(os.path.join(train_path_stutter, '*.wav')):\n",
    "    stutter_np = conv_audio_data(filename)\n",
    "    x_s.append(stutter_np)\n",
    "    y_s.append(1)\n",
    "\n",
    "for filename in glob.glob(os.path.join(train_path_fluent, '*.wav')):\n",
    "    fluent_np = conv_audio_data(filename)\n",
    "    x_f.append(fluent_np)\n",
    "    y_f.append(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  132039 KB |  132039 KB |  132039 KB |       0 B  |\\n|       from large pool |  131840 KB |  131840 KB |  131840 KB |       0 B  |\\n|       from small pool |     199 KB |     199 KB |     199 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  132039 KB |  132039 KB |  132039 KB |       0 B  |\\n|       from large pool |  131840 KB |  131840 KB |  131840 KB |       0 B  |\\n|       from small pool |     199 KB |     199 KB |     199 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  143360 KB |  143360 KB |  143360 KB |       0 B  |\\n|       from large pool |  141312 KB |  141312 KB |  141312 KB |       0 B  |\\n|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   11320 KB |   26246 KB |   89598 KB |   78277 KB |\\n|       from large pool |    9472 KB |   24320 KB |   87552 KB |   78080 KB |\\n|       from small pool |    1848 KB |    2046 KB |    2046 KB |     197 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |      80    |      80    |      80    |       0    |\\n|       from large pool |      31    |      31    |      31    |       0    |\\n|       from small pool |      49    |      49    |      49    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |      80    |      80    |      80    |       0    |\\n|       from large pool |      31    |      31    |      31    |       0    |\\n|       from small pool |      49    |      49    |      49    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       8    |       8    |       8    |       0    |\\n|       from large pool |       7    |       7    |       7    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       6    |       6    |       7    |       1    |\\n|       from large pool |       5    |       5    |       6    |       1    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
